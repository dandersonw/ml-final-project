\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{listings}
\usepackage{multicol}
\usepackage{url}
\usepackage{xeCJK}
\setCJKmainfont{IPAMincho}

\setlength{\parindent}{4em}
\setlength{\parskip}{1em}

\title{Transliterating English to Japanese Without Parallel Data}
\date{2019-03-01}
\author{Derick Anderson \\ anderson.de@husky.neu.edu
  \and Timothy Gillis \\ gillis.ti@husky.neu.edu }

\begin{document}

\pagenumbering{gobble}
\maketitle

\section*{Introduction}

We aim to learn to transliterate English to Japanese
without any parallel data.
That is to say,
given only monolingual corpora
and the tiniest insight about Japanese orthography
to learn how to represent English words in Japanese script.
Learning to transliterate with limited supervision has been well studied,
but there have been only limited attempts to learn without at least parallel data.
The key inspiration was the recent paper by
Conneau et al. \cite{Conneau2018WordTW}
in which word translations were learned with no parallel data
(or any other supervision).
Conneau et al. did not touch Japanese,
so we hope to first replicate their work on the Japanese-English language pair.
We then hope to discover an algorithm to learn to transliterate
using those (probably noisy) results as training data.

As big data becomes more readily available, the cost of manually labeling large
datasets emphasizes the need for unsupervised algorithms that perform as well if
not better than their supervised counterparts, and the cost of cleaning these
datasets highlights the need for algorithms to effectively handle noisy data as well.
Our project will touch upon both of these problems in the machine transliteration
sphere, specifically by first generating a Japanese-English dictionary in an
unsupervised way, then attempting to learn to transliterate from that noisy data.

Derick has a personal interest in Japanese, transliteration, and both together.
Timothy would like to gain experience in natural language processing and machine
translation.

\section*{Background}

\subsection*{Transliteration}

Transliteration is representing words
in a script or orthographic style
other than that with which they were originally represented.
Between close scripts like the Old English alphabet and the modern English alphabet
this can be a mechanical character to character mapping:
e.g. ``þe olde'' to ``ye olde''.
Between distant scripts
like the English alphabet and Japanese katakana
the task becomes more difficult.
Translation includes transliteration as a subtask,
although the relationship between the two
depends on the language pair, intended audience, and other factors.

In the literature on machine transliteration there is a distinction
between generative transliteration and transliteration extraction.
Generative transliteration learns a function for transliterating;
transliteration extraction just identifies pairs of strings
to be added to a transliteration dictionary
\cite{Karimi:2011:MTS:1922649.1922654}.
In this paper we will be doing generative transliteration.

In translating into both English and Japanese
probably the most common use of transliteration
is representing foreign proper nouns.
Because proper nouns are an open and varied class
there has been a lot of work on unsupervised learning to transliterate them
(e.g. \cite{Tao2006UnsupervisedNE}),
maybe for use in machine translation (e.g. \cite{Durrani2014IntegratingAU})
or cross-language information retrieval (e.g. \cite{10.1007/978-3-642-40087-2_29}).
A limitation of our proposed approach
is that we will not pay any special attention to proper nouns,
which often have their own conventions for transliteration.
% maybe we will want to?

The use of transliteration most relevant to this project
is the borrowing of words from foreign languages.
Like proper nouns,
some words may not have equivalents in every language,
and rather than create a neologism from native material (e.g. as done in Icelandic)
a foreign word might be adopted and used.

The work most closely related to ours is that of Ravi and Knight
\cite{Ravi2009LearningPM}
who learn to back-transliterate from Japanese to English
without any parallel data.
Back-transliteration is the process of
transforming a katakana string that represents an English word
back into the English word it represents.
The Ravi and Knight work seems to be followed up some other work
like a paper by Levinboim et. al. \cite{Levinboim2015ModelIR}
which aims to improve the same basic approach.
The key difference between their approach and ours
is that theirs requires a well trained model of Japanese and English phonetics.
We may choose to utilize an English phonetic model,
but don't require either.
Furthermore,
they impose constraints and start with favorable intializations
based on prior knowledge about transliteration.
We will utilize the fact
that English words are translated into katakana,
but hope to not inject any other prior knowledge.
Learning to transliterate into katakana
without knowledge of their pronunciation
or much aid from prior knowledge should be a step forward.

\subsection*{The Japanese-English Language Pair}

In modern orthography
Japanese represents foreign words
by approximating the pronunciation of the foreign word
in a syllabary \footnote{In a syllabary each character represents a syllable,
although katakana has some exceptions by that definition.} called katakana.
Native Japanese words and loanwords from Chinese
\footnote{Words of Sinitic origin are so common in Japanese that they not considered
  foreign in the same sense as words from English.}
are usually represented in scripts besides katakana:
the hiragana syllabary and kanji
\footnote{``Kanji'' is the Japanese name for Chinese characters.}.
The approximation of pronunciation is really quite approximate;
because Japanese has a relatively limited phonetic inventory (range of sounds used)
not all English sounds can be represented.
In the face of the complicated correspondence
between English spelling and English pronunciation
(to say nothing of international English variants)
Japanese people sometimes transliterate based on the spelling of a word
rather than the pronunciation.
An ideal system,
therefore,
will probably need to consider both phonetics and spelling.

Japanese has taken many loan words from English.
These can be common nouns (bed, ベッド),
verbs (join, ジョイン),
adjectives (sexy, セクシー),
or even sentence pieces (let's!, レッツ！).
Many (most?) loan words
are used in the same ways as their English equivalents,
although the meaning of some has diverged.
Japanese has also taken loanwords from other languages
that are written in katakana,
some of which may conflict with English words.
An example is ナトリウム,
translated from the Latin natrium,
meaning sodium (consider the Na elemental abbreviation).
The hope is that clever matching of English words
will allow useful transcription pairs to be found.

\subsection*{Word Translation Without Parallel Data}

Last year, Conneau et al. proposed a state-of-the-art unsupervised method for machine
translation without using any parallel corpora, that works well for both distant
language pairs (e.g. English-Chinese, English-Japanese) and pairs with limited parallel
data (e.g. English-Esperanto), also outperforming supervised methods on some language
pairs. This is accomplished by aligning the monolingual word embedding spaces for each
language in the pair.

Supervised methods attempt to learn a linear mapping $W$ between the source and target
space such that $WX-Y$ is minimized, where $X$ and $Y$ are the source and target word
embedding pairs, respectively. Because they attempt to learn $W$ without cross-lingual 
supervision, they use a domain-adversarial approach, where a discriminator is trained
to discriminate between translated (i.e. generated) words and words actually from the
target domain, and $W$ is simultaneously trained to "fool" the discriminator by making
the generated words as similar to the target words as possible.

While the learned $W$ roughly aligns the two embedding spaces, Conneau et al add two
modifications to further align the spaces. First, a refinement procedure is proposed
where the $W$ trained via the adversarial method is used to generate a synthetic
parallel vocabulary, which is then used to minimize $WX-Y$ in a supervised manner.
Second, they introduce a cross-domain similarity adaptation to mitigate the "hubness
problem" (i.e. in high dimensional spaces, some points tend to be nearest neighbors
to many other points).

\section*{Proposed Approach}

\subsection*{Unsupervised Word Translation}

We will first reproduce the word translation results of the Word Translation Without
Parallel Data paper on the Japanese-English language pair, using fastText Wikipedia
embeddings as the pre-trained word embedding spaces of dimension 300 to align,
a size 300 $\times$ 300 matrix for $W$, and a multilayer perceptron with two hidden
layers of size 2048 for the discriminator. For evaluation, we will use the
Japanese-English dictionary of about 35,000 word pairs released by the authors and
the protocol as outlined in the paper (i.e. measuring the number of times one of the
correct translations of a source word is retrieved, with precision@$k$ for $k = 1,5,10$).

Once aligned, a synthetic parallel vocabulary will be generated (as used in the
refinement procedure during training) and used as noisy ground truth data for
the transliteration portion of the project. This is assuming our results are comparable
to what was reported in the paper for similar distant language pairs
(e.g. \textasciitilde 60\% for Russian-English). If our results are not good enough,
we will instead use a purely supervised approach to generate the noisy pairs (i.e. by
minimizing $WX-Y$ as outlined in the paper's baseline). If the supervised solution is
still too noisy, the Japanese-English dictionary used for evaluation will be used instead.

While the code for this paper is released, the implementation is in PyTorch, so
TensorFlow will be used instead for novelty, and all training will be completed on an
NVIDIA GTX 1080 Ti graphics card.

\subsection*{Transliteration}

In order to not be blocked on
the completion of the word translation portion of the project,
we will substitute in some ground-truth data
while developing the transliteration half of the project.
Conveniently,
Facebook Research provides a ground truth English-Japanese dictionary
of the same sort as is used for their evaluation of word translation,
available on their GitHub
\footnote{https://github.com/facebookresearch/MUSE}.
It contains about 14,000 translations of an English word to a katakana string.
There is a slightly larger dataset available here
\footnote{https://github.com/eob/english-japanese-transliteration}
that we might choose to use.
CMU makes available a large dataset for English pronunciation
\footnote{http://www.speech.cs.cmu.edu/cgi-bin/cmudict}.

Considering just the bird's eye view of the task
as transforming a sequence of characters to another sequence of characters,
our first thought was to use a sequence-to-sequence model
like the well known Google neural machine translation model
\cite{Wu2016GooglesNM}.
Not surprisingly,
some people at Google did try that \cite{Rosca2016SequencetosequenceNN}
and found that the results were highly competitive.
Since attentional sequence-to-sequence models \cite{Bahdanau2015NeuralMT}
are so well known,
we won't describe the details here.

Treating words as just sequences of characters
means that we diverge from a lot of transliteration methods
in ignoring pronunciation.
The main motivation for that
is that we won't necessarily have pronunciation information for translation-pairs
that we get out of the word translation half of the project.
Something of a stretch goal is to validate the intuition
that considering both pronunciation and spelling will be helpful to transliteration.
Coincidentally,
the authors of the neural transliteration paper \cite{Rosca2016SequencetosequenceNN}
note that that seems like a good idea.
Considering pronunciation would be achieved by
training a sequence-to-sequence model to predict
the phoneme strings in the CMU pronunciation dataset.
The input to the transliteration model could then be
(most simply) appended with the predicted phoneme string.

For implementation,
Derick will use TensorFlow as that is the framework he is comfortable with.

Our personal opinion is that evaluating the correctness
of a transliterator is not that straightforward.
Nevertheless,
we will use a few straightforward measures
that appear in the transliteration literature.
The first is simply accuracy:
for what proportion of the input words
does the transliterator return the correct transliteration.
The second is Levenshtein distance:
the number of simple edits necessary to change the output to
the correct transliteration
\footnote{https://en.wikipedia.org/wiki/Levenshtein\_distance}.
The third is mean reciprocal rank (MRR):
a measure of how far down the list of possible results
(ordered in direction of decreasing probability)
the correct answer is
\footnote{https://en.wikipedia.org/wiki/Mean\_reciprocal\_rank}.
If we incorporate pronunciation or other features
we will perform a simple ablation study
to determine which features were useful.

Since the inaccuracy of word translation would appear as irreducible error
in evaluation on datasets created by that method,
to evaluate transliteration we will use ground truth data
from one of the English-Japanese transliteration datasets mentioned earlier.
A less easily solved issue is that
word translation might produce pairs with so much noise
that the model has a hard time learning or learns the wrong thing.
We don't have a good intuition for expected performance.
Considering all of the issues mentioned our proposed method might not work;
but it might well prove able to cut through the noise.

One possibility that we've considered,
in the event of results from word translation too poor to be used directly,
is to try and perform the matching of word pairs
jointly with learning transliteration.
In essence, bootstrapping the learning of transliteration.
For example,
train the transliterator first on the highest confidence pairs,
and then iteratively use that transliterator
to select more training examples from lower confidence pairs
by identifying which are most likely to be transliterations.
Another formulation:
consider that for each English word
we have a set of some katakana strings,
one of which is the correct transliteration.
If we knew which one were correct we could easily train the transliterator.
From that intuition is a short step to an EM algorithm.
Upadhyay et. al. \cite{Upadhyay2018BootstrappingTW}
bootstrap transliteration from annotator provided examples
in a way that we could potentially take ideas from.
Our worry is that extensive investigation into new algorithms
could start to creep out of scope for this project.

A more achievable fallback for the transliteration portion,
in the event of prohibitive inaccuracy of word transliteration,
is to attempt to verify
the pronunciation hypothesis I refer to as a stretch goal above.
Generalized tweaking of the model,
trying related sequence-to-sequence architectures,
and fiddling of that sort is also easily imagined.

\section*{Individual Tasks}

Derick will work on the transliteration half of the project.
He is useful for his domain knowledge.
He has worked on and will probably continue to work on
closely related projects,
but never anything of the same description.

Tim will work on the unsupervised word translation half of the project.
While he does not have direct experience in machine translation, he has
worked on projects with neural networks and the domain-adversarial training
approach that will be used.

This project is not part of or an extension of anything they have done.
It is not likely it will become a part of any future project.

\bibliography{doc}{}
\bibliographystyle{plain}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: t
%%% End:
