{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tf.enable_eager_execution()\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from transliteration import data, train, model_one, script, decode, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/derick/anaconda3/envs/tf-1.13/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data)\n",
    "batch_size = 128\n",
    "cmu_train_dataset = data.make_dataset('../data/tfrecord/cmu_train.tfrecord',\n",
    "                                      from_script='en',\n",
    "                                      to_script='cmu',\n",
    "                                      combine_words_proportion=0.3,\n",
    "                                      batch_size=batch_size)\n",
    "cmu_valid_dataset = data.make_dataset('../data/tfrecord/cmu_valid.tfrecord',\n",
    "                                      from_script='en',\n",
    "                                      to_script='cmu',\n",
    "                                      combine_words_proportion=0.3,\n",
    "                                      batch_size=batch_size)\n",
    "cmu_test_dataset = data.make_dataset('../data/tfrecord/cmu_test.tfrecord',\n",
    "                                     from_script='en',\n",
    "                                     to_script='cmu',\n",
    "                                     combine_words_proportion=0.3,\n",
    "                                     batch_size=batch_size)\n",
    "eob_train_dataset = data.make_dataset('../data/tfrecord/eob_train.tfrecord',\n",
    "                                      from_script='en',\n",
    "                                      to_script='ja',\n",
    "                                      batch_size=batch_size)\n",
    "eob_valid_dataset = data.make_dataset('../data/tfrecord/eob_valid.tfrecord',\n",
    "                                      from_script='en',\n",
    "                                      to_script='ja',\n",
    "                                      batch_size=batch_size)\n",
    "eob_test_dataset = data.make_dataset('../data/tfrecord/eob_test.tfrecord',\n",
    "                                     from_script='en',\n",
    "                                     to_script='ja',\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred)\n",
    "    return tf.reduce_mean(loss_ * mask)\n",
    "\n",
    "encoder_config = model_one.Config(lstm_size=480,\n",
    "                                  embedding_size=30,\n",
    "                                  attention_size=None,\n",
    "                                  vocab_size=script.SCRIPTS['en'].vocab_size)\n",
    "ja_decoder_config = model_one.Config(lstm_size=240,\n",
    "                                     embedding_size=30,\n",
    "                                     attention_size=120,\n",
    "                                     attention='monotonic_bahdanau',\n",
    "                                     vocab_size=script.SCRIPTS['ja'].vocab_size)\n",
    "cmu_decoder_config = model_one.Config(lstm_size=480,\n",
    "                                      embedding_size=30,\n",
    "                                      attention_size=240,\n",
    "                                      attention='monotonic_bahdanau',\n",
    "                                      vocab_size=script.SCRIPTS['cmu'].vocab_size)\n",
    "encoder = model_one.Encoder(encoder_config)\n",
    "ja_decoder = model_one.Decoder(ja_decoder_config)\n",
    "cmu_decoder = model_one.Decoder(cmu_decoder_config)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 ja_decoder=ja_decoder,\n",
    "                                 cmu_decoder=cmu_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss 21.166, Valid Loss 12.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K K EY2 T', 'D IH0 R IH1 K K AH0 N']], array([[-8.8619249 , -9.01395541]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 8.148, Valid Loss 5.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L IH0 D', 'D EH1 R IH0 K AH0 L AY2 Z']], array([[-9.19072141, -9.23511722]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 4.444, Valid Loss 4.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 Z', 'D EH1 R IH0 K AH0 L AY2 K IH2 NG K EH2 R IH0 K IH0 S UW1']], array([[ -7.37568376, -21.20046253]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 3.468, Valid Loss 3.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 Z', 'D EH1 R IH0 K AH0 L IH2 Z']], array([[-6.86713472, -7.56901041]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 2.950, Valid Loss 3.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 Z', 'D IH0 R IH1 K AH0 L AY2 Z UW2 D IH2 NG']], array([[ -7.92169074, -15.76549021]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 2.700, Valid Loss 2.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K OW2 L D OY2 Z', 'D EH1 R IH0 K AO2 R IY0 P OY2 Z']], array([[ -8.60524111, -11.27415145]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 2.471, Valid Loss 2.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 Z', 'D EH1 R IH0 K AH0 L D AY2 OY2 NG']], array([[-8.00446287, -9.93428174]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 2.304, Valid Loss 2.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K OW2 L D IH2 NG', 'D EH1 R IH0 K OW2 L D IH2 NG ER2']], array([[-7.59001536, -9.00992627]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 2.163, Valid Loss 2.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K ER0', 'D EH1 R IH0 K OW2 L D AW0 Z UW2 T ER0']], array([[ -3.72443988, -12.8405595 ]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 1.989, Valid Loss 2.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AO2 L IH0 D IH0 NG', 'D EH1 R IH0 K AO2 L IH0 D IH0 S']], array([[-8.24104696, -8.59390437]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 1.867, Valid Loss 2.530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D ER0 IH1 K AH0 L AY2 T AE2 NG', 'D EH1 R IH0 K OW2 L D OY2 Z']], array([[-7.37564243, -8.77276751]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 1.776, Valid Loss 2.539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AO2 R', 'D EH1 R IH0 K AO2 R IH0 F IH2 L D ER2 AY2 Z']], array([[ -4.07103087, -13.57692011]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 1.638, Valid Loss 2.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K', 'D EH1 R IH0 K Y UW2 EH2 L IH0 D IH0 S']], array([[ -3.03253228, -11.00656966]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 1.532, Valid Loss 2.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 F UH2 NG', 'D EH1 R IH0 K Y UW2 AY2 L D AO0 R AY1 P AO0 NG']], array([[ -8.96566794, -13.48465992]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 1.459, Valid Loss 2.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['D EH1 R IH0 K AH0 L AY2 F UH2 T S UW2 AH1 K AH0 L AY2 P', 'D EH1 R IH0 K AH0 L AY2 F UH2 T S UW2 AH1 K AH0 L AY2 F']], array([[-13.14848475, -13.41284089]]))\n"
     ]
    }
   ],
   "source": [
    "cmu_best_val_loss = None\n",
    "cmu_checkpoint = None\n",
    "for e in range(15):\n",
    "    loss = train.run_one_epoch(cmu_train_dataset,\n",
    "                               True,\n",
    "                               from_script='en',\n",
    "                               to_script='cmu',\n",
    "                               encoder=encoder,\n",
    "                               decoder=cmu_decoder,\n",
    "                               optimizer=optimizer,\n",
    "                               loss_function=loss_function)\n",
    "    valid_loss = train.run_one_epoch(cmu_valid_dataset,\n",
    "                                     False,\n",
    "                                     from_script='en',\n",
    "                                     to_script='cmu',\n",
    "                                     encoder=encoder,\n",
    "                                     decoder=cmu_decoder,\n",
    "                                     loss_function=loss_function)\n",
    "    if cmu_best_val_loss is None or valid_loss < cmu_best_val_loss:\n",
    "        cmu_best_val_loss = valid_loss\n",
    "        cmu_checkpoint = checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    print(\"Epoch {}: Train Loss {:.3f}, Valid Loss {:.3f}\".format(e, loss, valid_loss))\n",
    "    print(decode.transliterate(input_strs=['derick'],\n",
    "                               from_script='en',\n",
    "                               to_script='cmu',\n",
    "                               encoder=encoder,\n",
    "                               decoder=cmu_decoder,\n",
    "                               k_best=2,\n",
    "                               decoding_method=decode.beam_search_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.5199614, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "checkpoint.restore(cmu_checkpoint).assert_consumed()\n",
    "print(train.run_one_epoch(cmu_valid_dataset,\n",
    "                          False,\n",
    "                          from_script='en',\n",
    "                          to_script='cmu',\n",
    "                          encoder=encoder,\n",
    "                          decoder=cmu_decoder,\n",
    "                          loss_function=loss_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "encoder.save_weights('./training_checkpoints/encoder_big_cmu_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def run_some_epochs(epochs):\n",
    "    checkpoint_path = None\n",
    "    best_val_loss = None\n",
    "    for e in range(epochs):\n",
    "        loss = train.run_one_epoch(eob_train_dataset,\n",
    "                                   True,\n",
    "                                   from_script='en',\n",
    "                                   to_script='ja',\n",
    "                                   encoder=encoder,\n",
    "                                   decoder=ja_decoder,\n",
    "                                   optimizer=optimizer,\n",
    "                                   loss_function=loss_function)\n",
    "        valid_loss = train.run_one_epoch(eob_valid_dataset,\n",
    "                                         False,\n",
    "                                         from_script='en',\n",
    "                                         to_script='ja',\n",
    "                                         encoder=encoder,\n",
    "                                         decoder=ja_decoder,\n",
    "                                         loss_function=loss_function)\n",
    "        print(\"Epoch {}: Train Loss {:.3f}, Valid Loss {:.3f}\".format(e, loss, valid_loss))\n",
    "        print(decode.transliterate(input_strs=['derick'],\n",
    "                                       from_script='en',\n",
    "                                       to_script='ja',\n",
    "                                       encoder=encoder,\n",
    "                                       decoder=ja_decoder,\n",
    "                                       k_best=2,\n",
    "                                       decoding_method=decode.beam_search_decode))\n",
    "        if best_val_loss is None or valid_loss < best_val_loss:\n",
    "            best_val_loss = valid_loss\n",
    "            checkpoint_path = checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    return checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss 14.073, Valid Loss 7.238\n",
      "([['デリアキャン', 'デリアキャント']], array([[ -8.34756726, -10.81557959]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 6.051, Valid Loss 5.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['デリアク', 'ディアキャックション']], array([[ -4.41941084, -15.66589578]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 4.283, Valid Loss 4.851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリカック', 'ディリカックト']], array([[-6.76030186, -9.10081938]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 3.177, Valid Loss 4.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディアキャム', 'ディアキャング']], array([[-6.62485814, -9.01161444]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 2.400, Valid Loss 4.839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリキャックス', 'ディリキャックスポイトラフィュアップト']], array([[ -9.1408354 , -28.67769193]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=252329653, shape=(), dtype=float32, numpy=4.640569>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "checkpoint_path = run_some_epochs(5)\n",
    "checkpoint.restore(checkpoint_path).assert_consumed()\n",
    "train.run_one_epoch(eob_valid_dataset,\n",
    "                    False,\n",
    "                    from_script='en',\n",
    "                    to_script='ja',\n",
    "                    encoder=encoder,\n",
    "                    decoder=ja_decoder,\n",
    "                    loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss 2.367, Valid Loss 4.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリカ', 'ディリカム']], array([[-4.07673901, -4.35391801]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 1.808, Valid Loss 4.858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリキャブ', 'ディリキャブス']], array([[-6.21442242, -7.03158577]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 1.387, Valid Loss 4.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['デリコン', 'ディリキャックショョングホモーム']], array([[ -3.23265025, -23.32005098]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 1.038, Valid Loss 5.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリキャックショョングホモーム', 'ディリキャックショョングホディアム']], array([[-20.92677638, -23.05851698]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.842, Valid Loss 5.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリキャックショョングホモーム', 'ディリキャックショョングホモージャム']], array([[-20.22624055, -23.82038466]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.694, Valid Loss 5.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリック', 'ディリックプコーム']], array([[-3.66283104, -9.55650542]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.604, Valid Loss 5.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリック', 'ディリックグ']], array([[-3.02801965, -5.06569622]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.537, Valid Loss 5.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリックプォコーム', 'ディリックプコーマン']], array([[-9.13205026, -9.72117453]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.487, Valid Loss 5.952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリック', 'ディリックグ']], array([[-3.06644919, -4.70954791]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.457, Valid Loss 5.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['ディリックプコーム', 'ディリックプコール']], array([[-7.51793574, -8.276663  ]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=290142761, shape=(), dtype=float32, numpy=4.879769>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in encoder.layers:\n",
    "    layer.trainable = True\n",
    "checkpoint_path = run_some_epochs(10)\n",
    "checkpoint.restore(checkpoint_path).assert_consumed()\n",
    "train.run_one_epoch(eob_valid_dataset,\n",
    "                    False,\n",
    "                    from_script='en',\n",
    "                    to_script='ja',\n",
    "                    encoder=encoder,\n",
    "                    decoder=ja_decoder,\n",
    "                    loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_checkpoints/ckpt-18\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=297270050, shape=(), dtype=float32, numpy=4.629512>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore('./training_checkpoints/ckpt-16').assert_consumed()\n",
    "train.run_one_epoch(eob_valid_dataset,\n",
    "                    False,\n",
    "                    from_script='en',\n",
    "                    to_script='ja',\n",
    "                    encoder=encoder,\n",
    "                    decoder=ja_decoder,\n",
    "                    loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('../data/split/eob_pairs_valid.csv',\n",
    "                       keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5191675794085433"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = decode.transliterate(input_strs=valid_df['en'].values,\n",
    "                     from_script='en',\n",
    "                     to_script='ja',\n",
    "                     encoder=encoder,\n",
    "                     decoder=ja_decoder,\n",
    "                     k_best=10,\n",
    "                     num_beams=20,\n",
    "                     decoding_method=decode.beam_search_decode)\n",
    "evaluate.top_k_accuracy(valid_df['ja'].values, tr, k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-1.13]",
   "name": "conda-env-tf-1.13-py"
  },
  "name": "more_experiments.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
