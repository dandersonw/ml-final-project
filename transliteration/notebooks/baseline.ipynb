{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from transliteration import evaluate\n",
    "from transliteration.script import SCRIPTS\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    df = pd.read_csv(path, keep_default_na=False)\n",
    "    for c in df.columns:\n",
    "        if c in SCRIPTS:\n",
    "            df[c] = df[c].map(SCRIPTS[c].preprocess_string)\n",
    "    return df\n",
    "\n",
    "def memory_transliterator(df, from_script, to_script):\n",
    "    d = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        d[row[from_script]].append(row[to_script])\n",
    "    def result(string):\n",
    "        return d[string]\n",
    "    return result\n",
    "\n",
    "def metric_ceiling(full_df, test_df, from_script, to_script):\n",
    "    transliterator = memory_transliterator(full_df, from_script, to_script)\n",
    "    results = ([transliterator(s) for s in test_df[from_script]], None)\n",
    "    return {'acc@1': evaluate.top_k_accuracy(test_df[to_script], results, k=1),\n",
    "            'mrr@5': evaluate.mrr(test_df[to_script], results, k=5),\n",
    "            'cer': evaluate.character_error_rate(test_df[to_script],\n",
    "                                                 results,\n",
    "                                                 script_name='ja',\n",
    "                                                 use_script_cost=False),\n",
    "            'cer*': evaluate.character_error_rate(test_df[to_script],\n",
    "                                                 results,\n",
    "                                                 script_name='ja',\n",
    "                                                 use_script_cost=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path('/home/derick/code/ml-final-project/transliteration/data/')\n",
    "eob_full = load_df(data_dir / 'processed/eob_katakana_pairs.csv')\n",
    "muse_full = load_df(data_dir / 'processed/muse_katakana_pairs.csv')\n",
    "eob_test = load_df(data_dir / 'split/eob_pairs_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eob: {'acc@1': 0.9353760445682451, 'mrr@5': 0.9669916434540389, 'cer': 0.029601905410003404, 'cer*': 0.024923443348077577}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muse: {'acc@1': 0.9591294002379452, 'mrr@5': 0.97931392446404, 'cer': 0.02065232872810141, 'cer*': 0.016466473595087752}\n"
     ]
    }
   ],
   "source": [
    "print('eob: {}'.format(metric_ceiling(eob_full, eob_test, 'en', 'ja')))\n",
    "print('muse: {}'.format(metric_ceiling(muse_full, muse_full, 'en', 'ja')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-1.13]",
   "name": "conda-env-tf-1.13-py"
  },
  "name": "baseline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
